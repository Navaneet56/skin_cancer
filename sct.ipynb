{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0645\n",
      "Epoch 2, Loss: 0.9074\n",
      "Epoch 3, Loss: 0.8171\n",
      "Epoch 4, Loss: 0.7728\n",
      "Epoch 5, Loss: 0.7338\n",
      "Epoch 6, Loss: 0.6919\n",
      "Epoch 7, Loss: 0.6623\n",
      "Epoch 8, Loss: 0.6482\n",
      "Epoch 9, Loss: 0.6342\n",
      "Epoch 10, Loss: 0.6293\n",
      "Predicted Class: 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from transformers import SwinForImageClassification, SwinConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define dataset paths\n",
    "HAM10000_METADATA = \"D:\\\\Melanoma-Skin-Cancer-Detection-using-Swin-Transformer-main\\\\data\\\\HAM10000_metadata.csv\"\n",
    "IMAGE_DIR = \"D:\\\\Melanoma-Skin-Cancer-Detection-using-Swin-Transformer-main\\\\data\\\\HAM10000_images\"\n",
    "\n",
    "# Load and process metadata\n",
    "df = pd.read_csv(HAM10000_METADATA)\n",
    "label_mapping = {'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}\n",
    "df[\"label\"] = df[\"dx\"].map(label_mapping)\n",
    "\n",
    "# Split dataset into 80% train, 20% test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Custom Dataset Class\n",
    "class SkinCancerDataset(Dataset):\n",
    "    def __init__(self, img_dir, metadata, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "        self.valid_images = [(os.path.join(img_dir, f\"{row['image_id']}.jpg\"), row['label'])\n",
    "                             for _, row in metadata.iterrows() if os.path.exists(os.path.join(img_dir, f\"{row['image_id']}.jpg\"))]\n",
    "    def __len__(self):\n",
    "        return len(self.valid_images)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.valid_images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Create dataset & dataloaders\n",
    "train_dataset = SkinCancerDataset(IMAGE_DIR, train_df, transform=transform)\n",
    "test_dataset = SkinCancerDataset(IMAGE_DIR, test_df, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load Swin Transformer Model\n",
    "config = SwinConfig.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\", num_labels=7)\n",
    "model = SwinForImageClassification(config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=10)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"swin_transformer_skin_cancer.pth\")\n",
    "\n",
    "# Prediction Function\n",
    "def predict(image_path, model):\n",
    "    model.eval()\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Image not found!\")\n",
    "        return None \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image).logits\n",
    "        prediction = torch.argmax(output, dim=1).item()\n",
    "    return prediction\n",
    "\n",
    "# Example Prediction\n",
    "example_image = os.path.join(IMAGE_DIR, \"ISIC_0027413.jpg\")\n",
    "predicted_class = predict(example_image, model)\n",
    "if predicted_class is not None:\n",
    "    print(f\"Predicted Class: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
